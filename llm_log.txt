main: seed = 1702257670
llama_model_load: loading model from '/Users/nmccutchen/Documents/School/482/project/CSC482-Project/llm/resources/ggml-alpaca-7b-q4.bin' - please wait ...
llama_model_load: ggml ctx size = 6065.34 MB
llama_model_load: memory_size =  2048.00 MB, n_mem = 65536
llama_model_load: loading model part 1/1 from '/Users/nmccutchen/Documents/School/482/project/CSC482-Project/llm/resources/ggml-alpaca-7b-q4.bin'
llama_model_load: .................................... done
llama_model_load: model size =  4017.27 MB / num tensors = 291

system_info: n_threads = 12 / 14 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling parameters: temp = 1.000000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000


 [end of text]


main: mem per token = 14499844 bytes
main:     load time =   559.97 ms
main:   sample time =    72.60 ms
main:  predict time = 38129.72 ms / 51.67 ms per token
main:    total time = 39326.82 ms
